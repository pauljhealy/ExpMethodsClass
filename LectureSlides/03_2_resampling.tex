\include{LectureSlides/includes/metropolis_preamble}

\begin{document}

% Title page info
\title[Bootstrapping]{ExpEcon Methods: Resampling Methods\\
Permutation Tests \& Bootstrapping}
\author[ECON 8877]{ECON 8877\\P.J. Healy\\First version thanks to Sam Stelnicki} \color{metrop}
\institute[OSU]{}
\date[]{\vfill {\tiny Updated \today}}

\frame{\maketitle}


\section{Permutation Tests}

\begin{frame}{Example: The Permutation Test}
How it works:
\br
    \url{https://www.jwilber.me/permutationtest/}
\end{frame}

\begin{frame}{Permutation Test}
    \begin{itemize}
        \item Fisher (1935), Pitman (1937,1938)
        \item Resampling method where we use our data in different orders (without replacement) to test for differences between populations
        \item Example was for sample means
        \item Could do exact same for sample medians, modes, variances...
        \begin{itemize}
            \item \textit{Any} statistic of a sample!
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Assumptions \& Properties}
    \begin{itemize}
        \item Only assumption: observations are exchangeable 
        \begin{itemize}
            \item Joint dist'n: $F(Y_1,Y_2,Y_3) = F(Y_3,Y_1,Y_2)$
            \item Same marginals, ``symmetric'' correlation
            \item True if treatments are randomly assigned!
        \end{itemize}
        \item Permutation test is always \textbf{valid}
        \item The issues are\textbf{power} and \textbf{exactness}
        \begin{itemize}
            \item e.g., outliers can affect resampled distributions
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Two-Sample Framework}
\citet{ChungRomano2013}
\begin{itemize}
    \item Sample 1: $X_1,\ldots,X_m$ i.i.d. from $P$
    \item Sample 2: $Y_1,\ldots,Y_n$ i.i.d. from $Q$
    \item Let $Z=(Z_1,\ldots,Z_N)=(X_1,\ldots,X_m,Y_1,\ldots,Y_n)$, $N=m+n$
    \item Model/hypothesis: $(P,Q)\in \mathcal{P}$
    \item Important example: $\bar{\mathcal{P}}=\{(P,Q):\ P=Q\}$
    \item Permutations: $\pi:\{1,\ldots,N\}\rightarrow \{1,\ldots,N\}$, $\pi\in \mathbf{G}_N$
    \item Let $Z_\pi = (Z_{\pi(1)},\ldots,Z_{\pi(N)})$
    \item Test statistic: $T_{m,n}(Z)$ (eg, $T_{m,n}(Z)=\frac{1}{m}\sum_{i=1}^m X_i - \frac{1}{n}\sum_{i=1}^n Y_i$)
    \item $T_{m,n}(Z_\pi)$ calculated after permuting via $\pi$
    \item Order all $T_{m,n}(Z_\pi)$: $T_{m,n}^{(1)}\leq T_{m,n}^{(2)}\leq \cdots \leq T_{m,n}^{(N!)}$
    \item Given $\alpha$, threshold ranking is $k^*=(1-\alpha)N!$
    \item Permutation test function:
    $$
        \phi(Z) = \begin{cases}
            1 & T_{m,n}(Z) > T_{m,n}^{(k^*)} \\
            0 & T_{m,n}(Z) < T_{m,n}^{(k^*)}
        \end{cases}
    $$
\end{itemize}
\end{frame}

\begin{frame}{Two-Sample Framework}
\begin{itemize}
    \item If $(P,Q)\in \bar{\mathcal{P}}=\{(P,Q):\ P=Q\}$ then the test is exact:
    $$
        E_{P,Q}[\phi(X_1,\ldots,X_m,Y_1,\ldots,Y_n)] = \alpha
    $$
    \item But what if we assume $(P,Q)\in \mathcal{P}_0 \supset \bar{\mathcal{P}}$?
    \begin{itemize}
        \item Permuted data no longer has the same distribution as original
    \end{itemize}
    \item Test may not even be asymptotically exact
    \item Example: $\mathcal{P}_0 = \{(P,Q):\ \mu(P)=\mu(Q)\}$, $T_{m,n}(Z)=\sqrt{N}(\bar{X}_m-\bar{Y}_n)$
    \item \citet{Romano1990}: Rejection rate higher than $\alpha$ even with $N\rightarrow\infty$ unless
    \begin{enumerate}
        \item $m/n\rightarrow 1$ as $N\rightarrow\infty$, or
        \item variances of $P$ and $Q$ are equal
    \end{enumerate}
    \item Unbalanced samples: Rejecting the null might actually be due to different variances, not different means
\end{itemize}
\end{frame}

\begin{frame}{\citet{ChungRomano2013} Correction}
\citet{ChungRomano2013} offer a correction:
$$
    S_{m,n}(Z) = \frac{T_{m,n}(Z)}{V_{m,n}}
$$
where
$$
    V_{m,n}(Z) = \sqrt{\frac{N}{m}\hat{\sigma}_m^2(X_1,\ldots,X_m)+\frac{N}{n}\hat{\sigma}_n^2(Y_1,\ldots,Y_n)}
$$
For testing difference in means:
$$
    S_{m,n} = \frac{\sqrt{N}(\bar{X}_m-\bar{Y}_n)}{\frac{N}{m}S_X^2 + \frac{N}{n}S_Y^2}
$$
where
$$
    S_X^2 = \frac{1}{m-1}\sum_{i=1}^m (X_i-\bar{X}_m)^2
$$
Why? Distribution of $T_{m,n}(Z_\pi)$ is asymptotically normal with mean 0
\end{frame}

\begin{frame}{\citet{ChungRomano2013}}
\citet{ChungRomano2013}
    \begin{itemize}
        \item Different adjustments for different statistics
        \item Based on variance of the large-sample distribution, which is approximately normal
        \item Always divide $T_{m,n}$ by an estimator of that asymptotic variance
        \item Paper gives guidance for testing medians
    \end{itemize}
\end{frame}

\begin{frame}{Randomization Tests}
    \begin{itemize}
        \item You run ALL possible combinations of the data, rather than just a random subset
        \item Permutation test is a subset of randomization test
    \end{itemize}
\end{frame}

\begin{frame}{Young (2019)}
    \begin{itemize}
        \item Runs permutation tests for 53 different published AEA papers
        \item Finds 13-22\% fewer significant results than the methods used in the papers
        \item This increases to 33-49\% for multiple effects
    \end{itemize}
\end{frame}

\begin{frame}{Young (2019)}
    \begin{itemize}
        \item Runs permutation tests on regression coefficients of the previous paper
        \item Uses the Wald statistic and t-statistics
        \item Also runs bootstrap and jackknifes for all of these papers
    \end{itemize}
\end{frame}

\begin{frame}{Young (2019)}
    \begin{itemize}
        \item Key Takeaways: the design of experiments is really important for whether the p-values of resampling vs. statistical testing are similar
        \item Lots of treatments and interactions allows for more sensitivity to outliers and creates more volatility causing these methods to vary greatly
    \end{itemize}
\end{frame}







\section{Bootstrapping}

\begin{frame}{Bootstrapping - Efrom (1979)}
Goal: estimate a parameter of a distribution. e.g. median
    \begin{itemize}
        \item Resample your collected $n$-sized data \textit{with replacement} to produce M samples of n-sized data
        \item Each data point in your original sample has $\frac{1}{n}$ chance of being chosen
        \item Plot the distribution of observed parameter values.
        \item Estimate: mean of bootstrap dist'n
        \item Standard error: std. deviation of boostrap dist'n
        \item Confidence interval: 5th to 95th quantile 
        \item Completely non-parametric
    \end{itemize}
\end{frame}

\begin{frame}{Bootstrapping Assumptions}
    \begin{itemize}
        \item For the standard bootstrap method, observations are assumed to be independent
        \begin{itemize}
            \item Block bootstrapping was developed to deal with correlated data
        \end{itemize}
        \item Sample data needs to resemble the population its drawn from and sufficiently large
        \item Do not need to know the real distribution
        \item Sufficiently large: enough data to get to around 200 samples, but it's better to run as many bootstrap samples until your statistics converge
    \end{itemize}
\end{frame}

\begin{frame}{Bootstrapping Consistency}
    \begin{itemize}
        \item As long as the bootstrap variance converges, we have convergence of the entire distribution
        \begin{itemize}
            \item It seems like the only case where it won't is if the variance is infinite
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Using Bootstrapped Estimates}
    \begin{itemize}
        \item Bootstrapping itself is not a statistical test, but rather just estimating different parts of a distribution
        \item You can then use these estimates in a hypothesis test
    \end{itemize}
\end{frame}

\begin{frame}{Bootstrapping Mean}
    \begin{itemize}
        \item Compute sample mean. Is this truly the population mean?
        \item Step 1: Bootstrap some samples of the data
        \item Step 2: Find the mean of each of these samples
        \item Step 3: Plot these from smallest to largest to get a distribution of the bootstrapped mean
        \item Step 4: Find the confidence interval of these means and that's your estimate
    \end{itemize}
\end{frame}

\begin{frame}{Bootstrapping Standard Errors}
    \begin{itemize}
        \item Sample standard error may not be enough to give you insight to a statistical test - Monte Carlo Simulation
        \item Step 1: Bootstrap some samples of data
        \item Step 2: Calculate the statistic of interest that you want standard errors for i.e. mean
        \item Step 3: Calculate the standard deviation of each of these statistics
        \item Step 4: As the number of bootstrapped samples grows, this will become the bootstrapped standard error
    \end{itemize}
\end{frame}

\begin{frame}{Standard Deviation of Bootstrapped Statistics Calculation}
\centering
    $\hat{\sigma}_B = (\frac{\sum_{b=1}^{B}[\hat{\theta}^*(b)-\hat{\theta}^*(\cdot)]}{B-1})^{1/2}$ where $\hat{\theta}^*(\cdot) = \frac{\sum_{b=1}^{B}\hat{\theta}^*(b)}{B}$ \\
    \vspace{0.25 in}
    As B $\rightarrow \infty, \hat{\sigma}_B \rightarrow \sigma$
\end{frame}

\begin{frame}{Bootstrapping Difference of Two Sample Means}
    \begin{itemize}
        \item You have two samples: X and Y, with n and m observations. You want to know if the means are the same.
        \item Step 1: Compute $t=\frac{\bar{x}-\bar{y}}{\sqrt{\frac{\sigma_{x}^2}{n}+ \frac{\sigma_{y}^2}{m}}}$
        \item Step 2: Compute x' and y', where $x_i' = x_i - \bar{x} + \bar{z}$ and $y_i' = y_i - \bar{y} + \bar{z}$ where $\bar{z}$ is the mean of the joint sample
        \item Step 3: Draw bootstrapped sample of x' and y' and use those to compute test statistic
        \item Step 4: p-value = $\frac{\sum_{i=1}^{B}I[t_{i}>t]}{B}$
        \item Basically a permutation test, but sampling with replacement
    \end{itemize}
\end{frame}

\begin{frame}{When to Use?}
    \begin{itemize}
        \item When the sample size is too small for clear analysis
        \item When you do not have a clear understanding of the underlying population distribution
    \end{itemize}
\end{frame}

\begin{frame}{Example}
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
        \hline
        Original Data: & 13 & 8 & 1 & 11 & 7 & 4 & 15 & 12\\
        \hline
    \end{tabular} \\
\vspace{0.25in}
Mean: 8.875, std err: 1.6844
\end{frame}

\begin{frame}{Example}
        \begin{tabular}{|c|c|c|c|c|c|c|c|c|}
        \hline
        Original Data: & 13 & 8 & 1 & 11 & 7 & 4 & 15 & 12\\
        \hline
        Bootstrap 1: & 11 & 11 & 15 & 15 & 8 & 11 & 11 & 4\\
        \hline
        Bootstrap 2: & 4 & 15 & 1 & 4 & 4 & 8 & 13 & 11\\
        \hline
        Bootstrap 3: & 12 & 1 & 7 & 8 & 15 & 1 & 7 & 4\\
        \hline
        Bootstrap 4: & 12 & 12 & 7 & 8 & 8 & 1 & 15 & 1\\
        \hline
        Bootstrap 5: & 15 & 8 & 12 & 1 & 8 & 1 & 7 & 11\\
        \hline
    \end{tabular} \\
    \vspace{0.25in}
Means: 10.75, 7.5, 6.875, 8, 7.875
SE: 1.4911
\end{frame}

\begin{frame}{Code}
    \begin{itemize}
        \item Stata: bootstrap, reps(N): X Y Z
        \item Matlab: bootstrp(N,@stat,X,Y)
    \end{itemize}
\vspace{0.25in}
\includegraphics[width=\textwidth]{LectureSlides/graphics/boot/matlab.png}
\end{frame}

\begin{frame}{Jackknifing}
    \begin{itemize}
        \item Earlier resampling method than bootstrapping, where we no longer use the whole sample for resampling
        \item Rather, we remove one datapoint and calculate whatever statistic we want using the n-1 observations
        \begin{itemize}
            \item We do this for all possible samples of n-1, so we find a statistic removing every possible observation once
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Jackknifing Assumptions}
    \begin{itemize}
        \item Normally distributed data
        \begin{itemize}
            \item Small sample sizes may not be normal
        \end{itemize}
        \item Our resampled values are necessarily correlated
    \end{itemize}
\end{frame}

\begin{frame}{Bootstrap vs. Jackknife}
    \begin{itemize}
        \item Jackknife gives a more conservative estimate of standard error, but usually it's not as accurate as the bootstrap
        \item Jackknife gives same results every time, whereas bootstraps can change
    \end{itemize}
\end{frame}




\begin{frame}[allowframebreaks]
    \frametitle{References:}
    \small
    %\bibliographystyle{plainnat}
    \bibliographystyle{plainnat}
    \bibliography{pjbib}
\end{frame}




\end{document}